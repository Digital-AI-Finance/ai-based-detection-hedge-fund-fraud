[
  {
    "question": "What is the typical feature space dimensionality for fraud detection?",
    "options": [
      "a) 10--25",
      "b) 25--50",
      "c) 50--200",
      "d) 500--1000"
    ],
    "correct_answer": "c",
    "explanation": "Most fraud detection systems use 50--200 engineered features, combining return statistics (mean, volatility, skewness), Benford's law digits, autocorrelation measures, and network metrics. Higher dimensions risk overfitting.",
    "section_reference": "Appendix A1: Feature Engineering"
  },
  {
    "question": "What minimum return history is needed for reliable feature engineering?",
    "options": [
      "a) 6--12 months",
      "b) 24--36 months",
      "c) 48--60 months",
      "d) 72--84 months"
    ],
    "correct_answer": "b",
    "explanation": "Reliable statistical features require at least 24--36 months of return history. Shorter windows reduce statistical power for autocorrelation, volatility clustering, and anomaly detection. This creates the 'cold-start' problem.",
    "section_reference": "Appendix A1: Data Requirements"
  },
  {
    "question": "What is Benford's law first-digit frequency for d=1?",
    "options": [
      "a) ~30.1%",
      "b) ~17.6%",
      "c) ~11.1%",
      "d) ~25.0%"
    ],
    "correct_answer": "a",
    "explanation": "Benford's law predicts that the first digit d=1 appears with frequency log₁₀(1 + 1/1) ≈ 30.1%. Significant deviations in reported returns suggest manipulation. Fraudsters often under-report digit 1.",
    "section_reference": "Appendix A1: Benford's Law"
  },
  {
    "question": "Which method is used for chi-squared Benford testing?",
    "options": [
      "a) t-test on return means",
      "b) Kolmogorov--Smirnov test",
      "c) Compare observed vs expected digit frequencies",
      "d) ANOVA across periods"
    ],
    "correct_answer": "c",
    "explanation": "The chi-squared test compares observed first-digit frequencies from reported returns against Benford's theoretical distribution. High χ² values indicate anomalous digit patterns consistent with fabrication.",
    "section_reference": "Appendix A1: Statistical Testing"
  },
  {
    "question": "Why is PCA less common for feature reduction in fraud detection?",
    "options": [
      "a) Too slow computationally",
      "b) Requires too much data",
      "c) Cannot handle categorical features",
      "d) Loss of interpretability"
    ],
    "correct_answer": "d",
    "explanation": "Principal Component Analysis (PCA) reduces dimensionality but creates opaque linear combinations. Regulators require interpretable features (e.g., 'serial correlation', 'Sharpe ratio') for audit trails and legal justification.",
    "section_reference": "Appendix A1: Dimensionality Reduction"
  }
]
