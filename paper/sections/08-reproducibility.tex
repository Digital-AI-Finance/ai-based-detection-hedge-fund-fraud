% ==================== SECTION 8: REPRODUCIBILITY STATEMENT ====================
\section*{Reproducibility Statement}
\label{sec:reproducibility}

This paper is a qualitative survey of AI-based methods for hedge fund fraud detection. No original computational experiments were conducted, and therefore there are no experimental results requiring reproduction. However, to facilitate validation of our literature synthesis and to support future research building on this work, we provide the following transparency statement regarding our methodology and data sources.

\textit{Literature search protocol.} The survey followed a systematic search protocol informed by the SALSA methodology \citep{grant2009salsa} across five primary scholarly databases: Scopus, Web of Science, IEEE Xplore, the Social Science Research Network (SSRN), and Google Scholar. We employed a structured Boolean search query combining domain terms (``hedge fund,'' ``alternative investment,'' ``investment fund'') with fraud-related terms (``fraud,'' ``manipulation,'' ``anomaly'') and method terms (``machine learning,'' ``artificial intelligence,'' ``deep learning,'' ``neural network'') across titles, abstracts, and keywords. The search period covered publications from 2000 to 2025. The initial database searches yielded approximately 500 potentially relevant publications. Title and abstract screening reduced this set to 120 papers warranting full-text review. After detailed examination against inclusion criteria---peer-reviewed publications or widely cited preprints addressing fraud or anomaly detection in investment funds using AI/ML methods---80 papers met all criteria and form the core of this survey. An additional 25 papers on broader topics (financial regulation, general fraud detection, foundational ML methods) were included for contextual background, bringing the systematically identified corpus to 105 papers. Reference lists of highly cited papers were manually reviewed using snowballing to identify additional relevant studies. The full bibliography includes further foundational and methodological references cited for technical context. We emphasize that our qualitative synthesis focuses on methodological insights and contextual applicability rather than exhaustive enumeration.

\textit{Data sources.} All datasets referenced in this survey are publicly documented in their originating publications. The primary commercial hedge fund databases cited throughout the paper---Lipper TASS (now Refinitiv), Hedge Fund Research (HFR), BarclayHedge, and Morningstar---require institutional subscriptions and impose licensing restrictions that prohibit redistribution. These databases are, however, widely accessible to academic researchers through university library subscriptions and to practitioners through commercial licenses. Regulatory filing data from the U.S.\ Securities and Exchange Commission, including Form ADV, Form D, and Form 13F, are publicly accessible without restriction through the SEC's Electronic Data Gathering, Analysis, and Retrieval (EDGAR) system at \texttt{https://www.sec.gov/edgar}. European regulatory data under the Alternative Investment Fund Managers Directive (AIFMD) are available through national competent authorities, though access procedures vary by jurisdiction.

\textit{Limitations and constraints.} Several cited studies employ proprietary enforcement datasets maintained by regulatory agencies and cannot be independently verified due to confidentiality restrictions. In such cases, we rely on the methodological descriptions provided in the published papers and note where data access limitations prevent full reproducibility. Additionally, some commercial alternative data sources referenced in \Cref{sec:data-alternative}---including satellite imagery, geolocation analytics, and sentiment data---are available only through vendor-specific licenses and cannot be redistributed. We have documented these constraints where they arise and have prioritized discussion of methods that can be evaluated using publicly accessible data wherever possible.

\textit{Code and implementation details.} As a survey paper, we do not provide original code. However, many of the detection methods reviewed in \Cref{sec:literature} have publicly available implementations. Canonical machine learning methods---random forests, gradient boosting, support vector machines---are implemented in widely used libraries including scikit-learn (Python), caret (R), and XGBoost. Deep learning architectures are available through TensorFlow, PyTorch, and Keras. Graph neural network implementations are provided in PyTorch Geometric and the Deep Graph Library. Where specific papers have released code, we have cited the associated repositories.

Future researchers seeking to build on this work are encouraged to consult the research agenda in \Cref{sec:research-agenda}, which identifies the construction of public benchmark datasets (OP1) as the most critical enabler for reproducible progress in this field. Until such benchmarks exist, full end-to-end reproducibility of hedge fund fraud detection research will remain constrained by data access limitations that are endemic to the domain.
