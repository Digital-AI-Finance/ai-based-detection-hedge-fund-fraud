% ==================== SECTION 6: RESEARCH AGENDA AND OPEN PROBLEMS ====================
\section{Research Agenda and Open Problems}
\label{sec:research-agenda}

The preceding sections have documented a field that is simultaneously promising and immature. AI methods can detect statistical anomalies in hedge fund returns, extract fraud-relevant signals from regulatory filings, and model relational structures among market participants---yet the literature remains fragmented, the datasets are proprietary or nonexistent, and no deployed system has been rigorously evaluated against adversarial manipulation by sophisticated fund managers. This section crystallizes the most pressing gaps into ten concrete open problems, organized into three categories: data challenges (OP1--OP3), methodological challenges (OP4--OP7), and deployment challenges (OP8--OP10). For each problem, we articulate why it is uniquely difficult in the hedge fund context, suggest methodological approaches, and outline evaluation criteria. Collectively, these problems constitute Contribution~C3 of this paper: an actionable research roadmap designed to guide both academic researchers and industry practitioners toward high-impact work.

% ---------- 6.1 Data Challenges ----------
\subsection{Data Challenges}
\label{sec:agenda-data}

Progress in AI-based hedge fund fraud detection is fundamentally constrained by data availability. Unlike adjacent domains such as credit card fraud, where large-scale public benchmarks have catalyzed rapid methodological advancement, the hedge fund domain lacks standardized datasets, suffers from jurisdictional fragmentation, and relies on reporting cycles that introduce detection lags measured in months rather than milliseconds. The three problems in this category address these structural data deficiencies.

% ----- OP1 -----
\subsubsection{OP1: Benchmark Dataset Creation}
\label{sec:op1}

\textit{Problem.} No public benchmark dataset exists for hedge fund fraud detection. The credit card fraud community benefits from widely used benchmark datasets that have enabled reproducible comparison of hundreds of methods over the past decade. The financial statement fraud literature can draw on publicly available accounting data linked to SEC enforcement actions \citep{dimmock2012predicting}. Hedge fund fraud detection, by contrast, has no comparable resource: each study assembles its own proprietary dataset, uses different fraud labels, and reports results on non-overlapping fund populations, making cross-study comparison effectively impossible.

\textit{Why this is uniquely challenging for hedge funds.} The obstacles to benchmark creation are structural, not merely logistical. Fund-level return data are proprietary, maintained by commercial database vendors under restrictive licensing agreements that prohibit redistribution. The data are sparse---monthly returns rather than the millions of daily transactions available in payment fraud---and the total population is small, comprising roughly 10,000 to 15,000 funds in the major databases at any given time. Confirmed fraud labels are scarce and ambiguous: SEC enforcement actions capture only detected fraud, introducing survivorship bias in the label space itself, and the boundary between aggressive but legal return management and fraudulent misrepresentation is often adjudicated only after years of litigation.

\textit{Suggested approach.} We propose a two-track strategy. The first track involves constructing a synthetic benchmark that combines realistic return generation with injected fraud patterns. Regime-switching models calibrated to empirical hedge fund return distributions \citep{getmansky2004econometric} can generate plausible non-fraudulent return series, while fraud patterns---Ponzi-like return fabrication, NAV smoothing, and style drift---can be injected at rates and with characteristics calibrated to known enforcement cases. The second track involves developing an anonymization and differential privacy protocol that would enable regulators who possess enforcement-labeled datasets to release sanitized versions for research use. Generative models, including variational autoencoders \citep{kingma2014auto} and generative adversarial networks \citep{goodfellow2014generative}, trained on real regulatory data could produce synthetic datasets that preserve aggregate statistical properties---return distributions, cross-sectional correlations, and temporal dynamics---while provably protecting the identities of individual funds. Evaluation should be conducted on held-out synthetic fraud cases using out-of-sample detection metrics, with the benchmark designed to support multiple fraud types, class imbalance levels, and detection horizons.

% ----- OP2 -----
\subsubsection{OP2: Cross-Jurisdictional Data Integration}
\label{sec:op2}

\textit{Problem.} Hedge fund data are fragmented across regulatory jurisdictions, and no unified data infrastructure connects the reporting regimes of different national authorities. A fund domiciled in the Cayman Islands, managed from New York, with a European marketing passport and Asian prime brokerage relationships generates regulatory filings across multiple jurisdictions, each with different formats, frequencies, and disclosure requirements. An AI system operating within any single jurisdiction sees only a partial picture of the fund's operations.

\textit{Why this is uniquely challenging for hedge funds.} This fragmentation is qualitatively different from the cross-border challenges in banking or payment fraud. Banks operating internationally are subject to consolidated supervision under frameworks such as Basel III, and payment networks like SWIFT provide standardized messaging that enables cross-border transaction monitoring. Hedge funds, by contrast, exploit regulatory arbitrage deliberately: domiciliation in offshore centers such as the Cayman Islands, the British Virgin Islands, Luxembourg, or Ireland is chosen precisely because these jurisdictions impose lighter reporting requirements. The SEC's Form ADV captures US-registered advisers, the UK Financial Conduct Authority (FCA) maintains its own registry, and the European Securities and Markets Authority (ESMA) collects data under AIFMD---but these datasets are not linked, use different entity identifiers, and apply different classification schemes for fund strategies and risk metrics.

\textit{Suggested approach.} Federated learning frameworks offer a promising path forward, enabling multiple regulatory agencies to train a shared detection model without exchanging raw data. Each jurisdiction would train local model updates on its own regulatory data, and a central aggregation server would combine these updates to produce a global model that benefits from the combined information across all participating jurisdictions. Differential privacy guarantees can be layered onto the federated protocol to provide formal privacy bounds. The principal research challenges are twofold: first, developing entity resolution methods that link the same fund or manager across jurisdictions without sharing identifiable data; and second, handling the heterogeneity of reporting formats through standardized feature extraction pipelines that map jurisdiction-specific filings into a common representation space.

% ----- OP3 -----
\subsubsection{OP3: Real-Time Alternative Data Pipelines}
\label{sec:op3}

\textit{Problem.} Most existing detection approaches operate on monthly or quarterly data, introducing a detection lag that sophisticated fraudsters actively exploit. By the time a suspicious pattern becomes visible in a fund's monthly return series or quarterly regulatory filing, months of additional investor capital may have flowed into the fund, and the manager may have had ample opportunity to adjust behavior or abscond with assets.

\textit{Why this is uniquely challenging for hedge funds.} The detection lag in hedge fund surveillance is orders of magnitude greater than in other fraud domains. Banking fraud detection operates on real-time transaction streams with sub-second latency. Credit card fraud systems evaluate each transaction at the point of sale. Hedge fund surveillance, by contrast, depends on returns that are reported monthly with a typical lag of 30 to 60 days, regulatory filings that are updated annually or semi-annually, and holdings data that are disclosed quarterly with a 45-day delay. This temporal gap is not an implementation limitation but a structural feature of the hedge fund reporting regime.

\textit{Suggested approach.} The integration of real-time alternative data with periodic fund data offers a route to substantially reducing detection lag. News sentiment analysis using transformer-based language models \citep{devlin2019bert} can flag emerging concerns about specific funds or managers within hours of publication. Social media monitoring can detect investor complaints, whistleblower signals, and reputational deterioration in near-real time. Web scraping of fund marketing materials, employee turnover on professional networks, and litigation filings can provide early warning signals that precede changes in reported returns by months. The research challenge lies in developing fusion architectures that coherently integrate these high-frequency, noisy alternative data streams with the low-frequency, high-reliability periodic data that form the backbone of existing detection models. Attention-based architectures that learn to weight different data modalities according to their informativeness at different time horizons represent a promising direction \citep{vaswani2017attention}.


% ---------- 6.2 Methodological Challenges ----------
\subsection{Methodological Challenges}
\label{sec:agenda-methods}

Even with adequate data, the hedge fund fraud detection problem poses methodological challenges that distinguish it from fraud detection in other financial domains. The extreme rarity and heterogeneity of fraud events, the cold-start problem for new funds, temporal non-stationarity, and the need to fuse radically different data modalities each require tailored solutions that go beyond standard machine learning practice.

% ----- OP4 -----
\subsubsection{OP4: Extreme Class Imbalance at Small Scale}
\label{sec:op4}

\textit{Problem.} Hedge fund fraud detection faces a class imbalance problem that is qualitatively different from---and more severe than---the imbalance encountered in most other fraud detection domains. Standard oversampling techniques, developed for settings with abundant transaction data, fail to address the fundamental statistical challenges of the hedge fund context.

\textit{Why this is uniquely challenging for hedge funds.} Credit card fraud detection, the canonical class imbalance problem in the ML literature, operates at a base rate of approximately 0.1--0.5\% but compensates with millions or tens of millions of transactions, yielding thousands of positive examples for training. Hedge fund fraud has a comparable or lower base rate---estimates range from 0.5\% to 3\% depending on the fraud definition and time window---but operates on a total population of roughly 10,000 to 15,000 funds, yielding perhaps 50 to 100 labeled fraud cases across the entire historical record of enforcement actions. This is a small-$N$, high-dimensional, multi-modal problem. Standard oversampling methods such as SMOTE \citep{chawla2002smote} fail not merely because of imbalance but because the minority class is fundamentally heterogeneous: Ponzi schemes, NAV manipulation, and style drift produce entirely different statistical signatures, and interpolating between a Madoff-type fabrication and a Platinum Partners-type valuation fraud generates synthetic examples that correspond to no real fraud pattern. The problem is not too few fraud cases in aggregate; it is too few fraud cases \textit{per fraud type}, with types that are qualitatively distinct.

\textit{Suggested approaches.} Several research directions merit investigation. Few-shot learning methods, which learn to classify from very small numbers of examples by leveraging meta-learned representations, may enable fraud-type-specific detection with as few as five to ten labeled cases per type. Meta-learning across fraud types---training on a distribution of fraud detection tasks rather than a single classification problem---could produce models that generalize to novel fraud patterns from minimal examples. Semi-supervised contrastive learning, which learns representations by contrasting normal and anomalous funds in an embedding space without requiring hard labels for all examples, offers a way to exploit the large number of unlabeled funds. Transfer learning from related fraud domains (insurance fraud, financial statement fraud, money laundering) may provide useful inductive biases, though the degree of transferability across fraud domains remains an empirical question. Evaluation protocols must account for this heterogeneity: standard cross-validation on a pooled fraud class is insufficient, and researchers should adopt fraud-type-stratified splits that assess whether a model trained on known fraud types can detect held-out types.

% ----- OP5 -----
\subsubsection{OP5: Cold-Start Detection for New and Emerging Funds}
\label{sec:op5}

\textit{Problem.} Newly launched hedge funds lack the historical return data that serve as the primary input to most detection models. A fund with three months of track record provides insufficient statistical power for distributional tests, serial correlation analysis, or style-based anomaly detection. Yet the early period of a fund's life is precisely when fraud risk may be highest, as managers seek to establish credibility and attract capital.

\textit{Why this is uniquely challenging for hedge funds.} The cold-start problem in hedge fund detection differs fundamentally from cold-start problems in other domains. In banking, a new account inherits the institutional history and risk profile of the customer who opens it. In e-commerce fraud, a new user can be assessed through device fingerprinting, behavioral biometrics, and graph-based features from the first interaction. A new hedge fund, by contrast, is genuinely informationally opaque: it has no return history, no regulatory filing history, and no track record against which claims can be validated. Moreover, the hedge fund industry's incubation structures---in which managers operate ``paper portfolios'' or seed-stage vehicles before formally launching---allow selective reporting of only successful track records, a phenomenon closely related to backfill bias \citep{fung2009measurement, agarwal2011hedge}. The fund that appears in a database may be the survivor of multiple failed incubation attempts, and the reported inception-date returns may represent a cherry-picked history.

\textit{Suggested approaches.} Detection for new funds must rely on non-performance features. Operational due diligence characteristics---auditor quality, administrator independence, custody arrangements, and governance structures---are available from Form ADV at the time of registration and have demonstrated predictive power for subsequent fraud \citep{dimmock2012predicting, brown2008mandatory}. Transfer learning from funds with similar strategy descriptions, manager backgrounds, and organizational structures could provide prior distributions for expected return behavior, against which early realized returns can be evaluated. Network analysis of the manager's prior fund relationships---previous launches, co-manager affiliations, service provider networks---may reveal risk patterns that are invisible in the fund's own data. NLP applied to the fund's launch documents, offering memoranda, and marketing materials can assess the plausibility and consistency of stated strategies before any returns are generated. The research challenge is to develop models that integrate these heterogeneous non-performance signals into a coherent risk score that is calibrated against the base rate of fraud in new funds specifically.

% ----- OP6 -----
\subsubsection{OP6: Temporal Concept Drift and Adaptive Models}
\label{sec:op6}

\textit{Problem.} Fraud patterns evolve over time as perpetrators learn from detected schemes and adapt their methods to evade current detection approaches. A model trained on historical fraud cases may become progressively less effective as the distribution of fraud signals shifts, a phenomenon known as concept drift. In standard classification settings, concept drift is addressed through periodic retraining or online learning algorithms. In the hedge fund context, however, the problem is compounded by a source of legitimate drift that is absent in most other fraud domains.

\textit{Why this is uniquely challenging for hedge funds.} Hedge funds legitimately change their investment strategies in response to market conditions. A fund that begins as an equity long/short vehicle may pivot toward global macro during a period of heightened currency volatility, or a quantitative fund may shift from momentum to mean-reversion factors as market regimes change. These legitimate strategy transitions produce statistical signatures---changes in factor exposures, return distributions, and risk profiles---that closely resemble the signals associated with fraudulent strategy misrepresentation. In credit card fraud, spending pattern drift is slow and predictable, driven by lifecycle events and inflation. In banking fraud, behavioral drift reflects changes in channel usage and product adoption. Hedge fund drift, by contrast, can be sudden, large, and strategically motivated, making it fundamentally harder to distinguish legitimate adaptation from fraudulent concealment.

\textit{Suggested approaches.} Strategy-aware drift detection algorithms that incorporate information about market regimes and factor conditions represent a promising direction. Online learning methods with explicit drift detectors---such as the Adaptive Windowing (ADWIN) algorithm or the Drift Detection Method (DDM)---can be augmented with regime-switching models that identify whether observed changes in a fund's behavior are consistent with concurrent market dynamics or represent anomalous deviation. Factor-conditioned anomaly scores that normalize a fund's return characteristics against the behavior of peer funds pursuing similar strategies could reduce the false positive rate generated by legitimate strategy evolution. The key evaluation challenge is the construction of test sets that include both genuinely drifting fraud and legitimately adapting non-fraud, requiring either carefully annotated historical data or synthetic scenarios that embed both types of change.

% ----- OP7 -----
\subsubsection{OP7: Multi-Modal Fusion Architectures}
\label{sec:op7}

\textit{Problem.} Hedge fund fraud detection requires integrating information from multiple data modalities with fundamentally different characteristics: numerical return series, unstructured text from regulatory filings, high-dimensional portfolio snapshots, and graph-structured relational data. Each modality has different sampling frequencies, dimensionalities, and missing-data patterns. Existing approaches typically operate on a single modality or, at best, concatenate hand-engineered features from multiple sources, leaving substantial information on the table.

\textit{Why this is uniquely challenging for hedge funds.} No other financial entity generates the specific combination of data modalities that characterizes a hedge fund. Monthly returns are sparse, low-frequency time series with as few as 36 to 120 observations per fund. Quarterly regulatory filings are unstructured narrative documents that require NLP processing. Form 13F holdings are high-dimensional portfolio snapshots reported with a 45-day lag. Network data---prime broker relationships, auditor connections, manager affiliations---are inherently relational. Alternative data sources such as news sentiment and litigation records arrive at irregular, high-frequency intervals. Fusion must handle these radically different frequencies, dimensionalities, and missingness patterns simultaneously. This stands in contrast to, for example, e-commerce fraud, where all relevant signals (transaction amount, device, location, history) are available at the same granularity for every event.

\textit{Suggested approaches.} Attention-based multi-modal transformer architectures \citep{vaswani2017attention} that learn to weight different modalities dynamically according to their informativeness offer a principled framework for fusion. Cross-modal contrastive learning, which trains representations such that consistent signals across modalities are embedded nearby while inconsistencies are flagged, could specifically target the detection of funds whose textual descriptions contradict their quantitative behavior. Hierarchical fusion with modality-specific encoders---for example, recurrent networks for return series, pre-trained language models \citep{devlin2019bert} for text, and graph neural networks \citep{kipf2017semi, hamilton2017inductive} for relational data---can capture the inductive biases appropriate to each data type before combining representations at a higher level. The evaluation protocol should assess not only aggregate detection performance but also the marginal contribution of each modality, enabling researchers and practitioners to understand which data sources are most valuable and where investment in data acquisition would yield the greatest detection improvement.


% ---------- 6.3 Deployment Challenges ----------
\subsection{Deployment Challenges}
\label{sec:agenda-deployment}

Even a technically superior detection model is of limited practical value if it cannot withstand adversarial manipulation, explain its decisions to regulators and courts, or integrate effectively into human investigation workflows. The three problems in this category address the gap between academic proof-of-concept and operational deployment.

% ----- OP8 -----
\subsubsection{OP8: Adversarial Robustness Guarantees}
\label{sec:op8}

\textit{Problem.} Fraud detection is inherently an adversarial problem: the targets of detection actively seek to evade it. A detection model that achieves high accuracy on historical data may be rendered ineffective if a sophisticated manager reverse-engineers its decision boundary and adjusts reported behavior accordingly. Adversarial robustness---the ability of a model to maintain performance under deliberate input manipulation---is therefore a necessary condition for deployment, not merely a desirable property.

\textit{Why this is uniquely challenging for hedge funds.} The adversarial dynamics in hedge fund fraud detection are qualitatively different from those in other fraud domains. Credit card fraudsters, while numerous, are typically unsophisticated and operate at scale, relying on volume rather than precision. Hedge fund managers contemplating fraud are, by contrast, among the most quantitatively sophisticated actors in the financial system. They employ PhD-level quantitative analysts, have access to the same statistical and machine learning tools used to build detection models, and can afford to hire consultants who specialize in regulatory compliance and forensic accounting. The adversary in this domain is not a script kiddie but a well-resourced, highly educated professional who may be able to simulate detection models, identify their decision boundaries, and engineer return series that evade detection while maintaining the appearance of legitimacy. This makes the adversarial game qualitatively different and demands robustness guarantees that go beyond standard perturbation-based adversarial training.

\textit{Suggested approaches.} Certified robustness bounds that provide formal guarantees on the maximum change in model output under bounded input perturbations offer a principled foundation. Game-theoretic adversarial modeling, in which the detection system and the fraudster are modeled as players in a repeated game with asymmetric information, can capture the strategic dynamics of hedge fund fraud more faithfully than standard adversarial training paradigms. Red-teaming exercises in which financial domain experts attempt to construct return series that evade specific detection models would provide empirical assessments of robustness. Robust ensemble methods that combine diverse model families---statistical tests, tree-based classifiers, deep networks, and network-based detectors---can increase the difficulty of evasion by requiring an adversary to simultaneously fool multiple independent detection mechanisms. Research in this area should evaluate robustness not only against generic adversarial perturbations but against economically meaningful manipulations: return series that satisfy standard statistical plausibility checks, filings that pass automated consistency validation, and network structures that mimic legitimate fund-of-funds arrangements.

% ----- OP9 -----
\subsubsection{OP9: Explainability Without Sacrificing Performance}
\label{sec:op9}

\textit{Problem.} Regulatory requirements for AI systems used in financial surveillance demand transparency: the EU AI Act requires that high-risk AI systems produce outputs that are ``sufficiently transparent to enable deployers to interpret the system's output and use it appropriately,'' and SEC enforcement actions must be supported by evidence that can withstand legal challenge. Yet the most powerful detection methods---deep neural networks, ensemble models, graph neural networks---are precisely those that resist straightforward explanation. The field faces a tension between detection power and interpretive transparency that current post-hoc explainability methods do not fully resolve.

\textit{Why this is uniquely challenging for hedge funds.} The explainability requirements for hedge fund fraud detection are more stringent than for most other AI applications in finance. In credit scoring, the explainability bar is well established by decades of regulatory guidance, adverse action notice requirements, and settled law. In hedge fund fraud detection, the regulatory framework is newer and less settled: there is no standardized examination protocol for AI-assisted surveillance, enforcement actions based on AI-generated evidence are largely untested in court, and the legal standards for admissibility of algorithmic suspicion vary across jurisdictions. Explainability must therefore satisfy multiple audiences simultaneously: SEC or FCA examiners who need to understand why a fund was flagged during a routine examination, enforcement attorneys who need to present evidence in administrative proceedings, and potentially judges and juries in contested civil or criminal cases. This is a materially higher bar than the compliance dashboards that suffice for standard anti-money laundering systems. \citet{rudin2019stop} argued forcefully that high-stakes domains should prefer inherently interpretable models over post-hoc explanations of black boxes; the hedge fund fraud context exemplifies this argument.

\textit{Suggested approaches.} Inherently interpretable architectures such as neural additive models and explainable boosting machines offer a promising middle ground, providing nonlinear modeling capacity while maintaining per-feature transparency. Where complex models are necessary for performance, faithful distillation---training an interpretable student model to approximate the decision boundary of a complex teacher model---can provide explanations that are provably consistent with the teacher's behavior. Post-hoc methods such as SHAP \citep{lundberg2017unified} and LIME \citep{ribeiro2016why} provide local explanations for individual predictions, but their faithfulness to the underlying model has been questioned in adversarial settings \citep{arrieta2020explainable}. Attention-based explanations that highlight which return periods, filing passages, or network connections contributed most to a fraud score offer a natural explanation format for financial investigators. A critical research direction is the development of standardized explanation templates designed specifically for regulatory audiences---structured reports that map model outputs to the specific fraud indicators that examiners are trained to evaluate, bridging the gap between ML output and regulatory workflow.

% ----- OP10 -----
\subsubsection{OP10: Human-AI Collaboration in Fraud Investigation}
\label{sec:op10}

\textit{Problem.} No AI system will replace human judgment in hedge fund fraud investigation in the foreseeable future. Detection models generate alerts; human investigators must evaluate those alerts, conduct follow-up analysis, and make enforcement decisions. The effectiveness of the overall system therefore depends not only on model accuracy but on the quality of the human-AI interaction: how alerts are prioritized, communicated, and acted upon, and how investigator feedback is incorporated to improve future detection.

\textit{Why this is uniquely challenging for hedge funds.} Hedge fund fraud investigation is resource-intensive and cognitively demanding. A single investigation may require months of document review, forensic accounting analysis, and expert consultation. False positives are not merely an inconvenience---they consume scarce examination resources that could be directed toward genuinely suspicious funds. At the same time, the consequences of false negatives are severe: undetected fraud can compound over years, as the Madoff case demonstrated. The base rate of fraud is low enough that even a model with apparently high precision may generate more false positives than true positives in absolute terms, a well-known consequence of applying high-accuracy classifiers to rare events. Investigator alert fatigue---the tendency to discount or ignore alerts after experiencing repeated false positives---is a serious operational risk that can negate the benefits of even a technically capable detection system.

\textit{Suggested approaches.} Active learning frameworks, in which the model selectively queries investigators about the cases most likely to improve its decision boundary, can simultaneously reduce alert volume and maximize the information gained from each investigation. Prioritized alert queues that present cases ranked by both fraud probability and estimated financial impact can help investigators allocate their time to the highest-value cases. Investigation-ready explanation packages---structured reports that include the model's fraud score, the contributing features with their SHAP values, relevant historical comparisons to known fraud cases, and suggested lines of inquiry---can reduce the time from alert to actionable investigation. Adaptive threshold management, which adjusts the alert generation threshold based on current investigator capacity and historical precision at different operating points, can maintain a sustainable alert volume. Feedback loops that allow investigators to label alerts as true positives, false positives, or inconclusive and retrain the model accordingly are essential for long-term system improvement. The research challenge is to evaluate these human-AI interaction designs in realistic operational settings, which may require collaboration with regulatory agencies willing to conduct controlled trials.


% ---------- 6.4 Prioritization and Synthesis ----------
\subsection{Prioritization and Path Forward}
\label{sec:agenda-synthesis}

Not all open problems are equally urgent or equally tractable. We propose a prioritization based on two criteria: \textit{impact}, defined as the degree to which solving the problem would unlock progress on other problems, and \textit{feasibility}, defined as the degree to which current methods and data can support meaningful research. \Cref{tab:op-priority} summarizes this assessment.

\begin{table}[t]
\centering
\caption{Prioritization of open problems by impact and feasibility. Problems marked as preconditions enable progress on dependent problems.}
\label{tab:op-priority}
\small
\begin{tabularx}{\textwidth}{llccX}
\toprule
\textbf{ID} & \textbf{Problem} & \textbf{Impact} & \textbf{Feasibility} & \textbf{Dependencies} \\
\midrule
OP1 & Benchmark dataset & Critical & Medium & Precondition for OP4, OP6, OP7 \\
OP4 & Class imbalance at small $N$ & Critical & Medium & Precondition for all supervised methods \\
OP9 & Explainability & High & Medium--High & Required for OP10, regulatory deployment \\
OP5 & Cold-start detection & High & Medium & Benefits from OP1 \\
OP7 & Multi-modal fusion & High & Medium & Benefits from OP1 \\
OP8 & Adversarial robustness & High & Low--Medium & Requires OP1 for evaluation \\
OP6 & Concept drift & Medium--High & Medium & Benefits from OP1 \\
OP10 & Human-AI collaboration & Medium--High & Low & Requires regulatory partnerships \\
OP3 & Real-time data pipelines & Medium & Low--Medium & Data access constraints \\
OP2 & Cross-jurisdictional integration & Medium & Low & Requires multi-regulator coordination \\
\bottomrule
\end{tabularx}
\end{table}

Two problems stand out as critical preconditions. OP1 (benchmark dataset creation) is foundational because without a shared evaluation resource, the field cannot conduct reproducible comparisons, and progress on nearly every other problem---class imbalance methods (OP4), drift detection (OP6), fusion architectures (OP7), and adversarial robustness (OP8)---is impeded by the inability to benchmark against common data. OP4 (extreme class imbalance) is equally critical because the small-$N$, heterogeneous-positive-class nature of the problem invalidates the standard supervised learning assumptions that underpin most detection methods; any methodological advance that does not grapple with this reality will fail to translate from laboratory settings to operational deployment.

The feasibility assessment reveals an important structural constraint: the most impactful problems---OP2 (cross-jurisdictional integration) and OP10 (human-AI collaboration)---are also those that require institutional collaboration that no single research group can orchestrate. Regulatory agencies possess the enforcement-labeled data needed for benchmark creation (OP1), the cross-border relationships needed for federated learning (OP2), and the operational environments needed for human-AI evaluation (OP10). Academic researchers bring methodological expertise in deep learning, adversarial robustness, and explainability. The hedge fund industry contributes domain knowledge about strategy evolution, operational due diligence, and the practical realities of fund management. Progress on this research agenda therefore demands a collaborative model that brings these three communities together---through shared data initiatives, regulatory sandboxes for AI testing, and joint research programs---because no single community possesses the data, methods, and operational context needed to address these problems in isolation.
